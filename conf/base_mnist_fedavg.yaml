# ══════════════════════════════════════════════════════════════════════════════
# FLORA Test Configuration – Base MNIST Setup
#
# This configuration provides baseline settings for testing federated learning
# with a simple CNN on the MNIST dataset. 
# It includes sensible defaults for the model architecture, dataset configuration,
# and training parameters.
#
# Configuration inheritance:
# This file extends base.yaml which defines the complete framework structure.
# We only need to override specific values here.
# The base handles all the object instantiation patterns and _target_ specifications.
#
# To customize: extend this config and override the sections you need to change.
# ══════════════════════════════════════════════════════════════════════════════

defaults:
  - base # Include base framework config with inline defaults
  - algorithm: fedavg # Apply fedavg algorithm configuration
  - model: simple_cnn # Apply simple CNN model configuration
  - datamodule: mnist # Apply MNIST dataset configuration
  - _self_

# ─────────────────────────────────────────
# Engine Overrides

global_rounds: 2

# ─────────────────────────────────────────
# Algorithm Overrides

algorithm:
  local_lr: 0.01
  max_epochs_per_round: 2

# ─────────────────────────────────────────
# Model Overrides

model:
  backbone:
    in_channels: 1 # MNIST has 1 channel
  head:
    num_classes: 10 # 10 digits

# ─────────────────────────────────────────
# DataModule Overrides

datamodule:
  train:
    batch_size: 16
  eval:
    batch_size: 16

# ─────────────────────────────────────────
# Schedules Overrides

schedules:
  aggregation:
    round_end: true # Aggregate every round
    epoch_end: false
    batch_end: false

  evaluation:
    experiment_start: false
    experiment_end: false
    pre_aggregation: false
    post_aggregation: true # Evaluate after every aggregation
